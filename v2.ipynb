{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully split into training, validation, and test sets!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define directories\n",
    "base_dir = Path('Dataset')\n",
    "output_dir = Path('SplitV2')\n",
    "train_dir, val_dir, test_dir = (output_dir / 'train', output_dir / 'validation', output_dir / 'test')\n",
    "\n",
    "# Ratios\n",
    "train_ratio, val_ratio, test_ratio = 0.8, 0.1, 0.1\n",
    "\n",
    "# Create necessary directories\n",
    "for dir_path in [train_dir, val_dir, test_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_image(src, dst):\n",
    "    \"\"\"Copy file from source to destination.\"\"\"\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "for class_path in base_dir.iterdir():\n",
    "    if class_path.is_dir():  # Only process directories (class folders)\n",
    "        images = [img for img in class_path.iterdir() if img.is_file()]  # Filter files\n",
    "        \n",
    "        if len(images) < 2:  # Skip classes with very few images\n",
    "            print(f\"Skipping {class_path.name}: Not enough images to split.\")\n",
    "            continue\n",
    "\n",
    "        # Split dataset\n",
    "        train_imgs, temp_imgs = train_test_split(images, test_size=(1 - train_ratio), random_state=42)\n",
    "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42)\n",
    "\n",
    "        # Create class subdirectories\n",
    "        for subdir in [train_dir, val_dir, test_dir]:\n",
    "            (subdir / class_path.name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copy files using multithreading\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for img_set, target_dir in zip([train_imgs, val_imgs, test_imgs], [train_dir, val_dir, test_dir]):\n",
    "                executor.map(copy_image, img_set, [target_dir / class_path.name / img.name for img in img_set])\n",
    "\n",
    "print(\"Dataset successfully split into training, validation, and test sets!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34173 images belonging to 4 classes.\n",
      "Found 4273 images belonging to 4 classes.\n",
      "Found 4274 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,  # Augment dataset by flipping images\n",
    "    fill_mode='nearest'  # Avoid artifacts when transforming images\n",
    ")\n",
    "\n",
    "# Validation & Test: No augmentation, just rescaling\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,  # Increase if memory allows\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "validation_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,  # Maintain order for evaluation\n",
    "    interpolation='bilinear'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">423,748</span> (1.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m423,748\u001b[0m (1.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,788</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m422,788\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25405s\u001b[0m 48s/step - accuracy: 0.5582 - loss: 1.0680 - val_accuracy: 0.5818 - val_loss: 1.0019 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1772s\u001b[0m 3s/step - accuracy: 0.6849 - loss: 0.7911 - val_accuracy: 0.6101 - val_loss: 1.0538 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1795s\u001b[0m 3s/step - accuracy: 0.7432 - loss: 0.6654 - val_accuracy: 0.6892 - val_loss: 0.7816 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1940s\u001b[0m 4s/step - accuracy: 0.7742 - loss: 0.5906 - val_accuracy: 0.7166 - val_loss: 0.8180 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1798s\u001b[0m 3s/step - accuracy: 0.8085 - loss: 0.5212 - val_accuracy: 0.7821 - val_loss: 0.6073 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1792s\u001b[0m 3s/step - accuracy: 0.8262 - loss: 0.4810 - val_accuracy: 0.7618 - val_loss: 0.7470 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1724s\u001b[0m 3s/step - accuracy: 0.8359 - loss: 0.4486 - val_accuracy: 0.8287 - val_loss: 0.4789 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1773s\u001b[0m 3s/step - accuracy: 0.8448 - loss: 0.4255 - val_accuracy: 0.7110 - val_loss: 0.8519 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1690s\u001b[0m 3s/step - accuracy: 0.8511 - loss: 0.3966 - val_accuracy: 0.8402 - val_loss: 0.4556 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1718s\u001b[0m 3s/step - accuracy: 0.8588 - loss: 0.3852 - val_accuracy: 0.8404 - val_loss: 0.4209 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1716s\u001b[0m 3s/step - accuracy: 0.8628 - loss: 0.3750 - val_accuracy: 0.7021 - val_loss: 1.1636 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1740s\u001b[0m 3s/step - accuracy: 0.8636 - loss: 0.3693 - val_accuracy: 0.8647 - val_loss: 0.3606 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1807s\u001b[0m 3s/step - accuracy: 0.8708 - loss: 0.3484 - val_accuracy: 0.8711 - val_loss: 0.3515 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2224s\u001b[0m 4s/step - accuracy: 0.8760 - loss: 0.3348 - val_accuracy: 0.7931 - val_loss: 0.6366 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1836s\u001b[0m 3s/step - accuracy: 0.8801 - loss: 0.3274 - val_accuracy: 0.8184 - val_loss: 0.5481 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1838s\u001b[0m 3s/step - accuracy: 0.8766 - loss: 0.3254 - val_accuracy: 0.7363 - val_loss: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1803s\u001b[0m 3s/step - accuracy: 0.8876 - loss: 0.2966 - val_accuracy: 0.8799 - val_loss: 0.3115 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1709s\u001b[0m 3s/step - accuracy: 0.8910 - loss: 0.2833 - val_accuracy: 0.8823 - val_loss: 0.3322 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9270s\u001b[0m 17s/step - accuracy: 0.8899 - loss: 0.2849 - val_accuracy: 0.8989 - val_loss: 0.2700 - learning_rate: 5.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1813s\u001b[0m 3s/step - accuracy: 0.8951 - loss: 0.2707 - val_accuracy: 0.8935 - val_loss: 0.2845 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1814s\u001b[0m 3s/step - accuracy: 0.8907 - loss: 0.2742 - val_accuracy: 0.8989 - val_loss: 0.2729 - learning_rate: 5.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1785s\u001b[0m 3s/step - accuracy: 0.8954 - loss: 0.2688 - val_accuracy: 0.8942 - val_loss: 0.2712 - learning_rate: 5.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1786s\u001b[0m 3s/step - accuracy: 0.8988 - loss: 0.2561 - val_accuracy: 0.9048 - val_loss: 0.2382 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1798s\u001b[0m 3s/step - accuracy: 0.8992 - loss: 0.2458 - val_accuracy: 0.9008 - val_loss: 0.2637 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1785s\u001b[0m 3s/step - accuracy: 0.9000 - loss: 0.2495 - val_accuracy: 0.8994 - val_loss: 0.2531 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1755s\u001b[0m 3s/step - accuracy: 0.8987 - loss: 0.2511 - val_accuracy: 0.9015 - val_loss: 0.2465 - learning_rate: 2.5000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1781s\u001b[0m 3s/step - accuracy: 0.9019 - loss: 0.2394 - val_accuracy: 0.9080 - val_loss: 0.2283 - learning_rate: 1.2500e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2126s\u001b[0m 4s/step - accuracy: 0.9018 - loss: 0.2376 - val_accuracy: 0.9019 - val_loss: 0.2385 - learning_rate: 1.2500e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1822s\u001b[0m 3s/step - accuracy: 0.9036 - loss: 0.2340 - val_accuracy: 0.8954 - val_loss: 0.2573 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1786s\u001b[0m 3s/step - accuracy: 0.9046 - loss: 0.2315 - val_accuracy: 0.8877 - val_loss: 0.2848 - learning_rate: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d93ebc8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    # Convolutional Block 1\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Feature Extraction\n",
    "    GlobalAveragePooling2D(),  # Replaces Flatten to reduce overfitting\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Helps prevent overfitting\n",
    "\n",
    "    # Output Layer\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile model with Adam optimizer & learning rate scheduler\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,  # Increased epochs for better learning\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_modelv2.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Saves as a single file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"my_modelv2.h5\")  # Saves as a single file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEcomistModelV2.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"EcomistModelV2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: models/saved\\EcomistModelV2.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define the target folder\n",
    "save_dir = \"models/saved\"  # Change this to your desired folder\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Sample model (Replace this with your actual trained model)\n",
    "model = Sequential()  # Use your trained model instead\n",
    "\n",
    "# Define the full path to save the model\n",
    "model_path = os.path.join(save_dir, \"EcomistModelV2.h5\")\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"Model saved at: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EcomistModelV2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"Model_V2/models/saved/EcomistModelV2.h5\")\n",
    "\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"ModelV2.keras\")\n",
    "\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Shows your current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def total_files(folder_path):\n",
    "    return len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "Train_healthy = \"Split/train/Healthy\"\n",
    "Train_bacterial = \"Split/train/Bacterial\"\n",
    "Train_Fungal = \"Split/train/Fungal\"\n",
    "Train_Lettuce = \"Split/train/Lettuce\"\n",
    "\n",
    "Test_healthy = \"Split/test/Healthy\"\n",
    "Test_bacterial = \"Split/test/Bacterial\"\n",
    "Test_Fungal = \"Split/test/Fungal\"\n",
    "Test_Lettuce = \"Split/test/Lettuce\"\n",
    "\n",
    "Valid_healthy = \"Split/validation/Healthy\"\n",
    "Valid_bacterial = \"Split/validation/Bacterial\"\n",
    "Valid_Fungal = \"Split/validation/Fungal\"\n",
    "Valid_Lettuce = \"Split/validation/Lettuce\"\n",
    "\n",
    "print(\"Number of healthy leaf images in training set:\", total_files(Train_healthy))\n",
    "print(\"Number of bacterial leaf images in training set:\", total_files(Train_bacterial))\n",
    "print(\"Number of fungal leaf images in training set:\", total_files(Train_Fungal))\n",
    "print(\"Number of Lettuce images in training set:\", total_files(Train_Lettuce))\n",
    "\n",
    "print(\"=\"*90)\n",
    "\n",
    "print(\"Number of healthy leaf images in test set:\", total_files(Test_healthy))\n",
    "print(\"Number of bacterial leaf images in test set:\", total_files(Test_bacterial))\n",
    "print(\"Number of fungal images in test set:\", total_files(Test_Fungal))\n",
    "print(\"Number of Lettuce images in training set:\", total_files(Test_Lettuce))\n",
    "\n",
    "print(\"=\"*90)\n",
    "\n",
    "print(\"Number of healthy leaf images in validation set:\", total_files(Valid_healthy))\n",
    "print(\"Number of bacterial leaf images in validation set:\", total_files(Valid_bacterial))\n",
    "print(\"Number of fungal images in validation set:\", total_files(Valid_Fungal))\n",
    "print(\"Number of Lettuce images in training set:\", total_files(Valid_Lettuce))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "image_path = \"Split/train/Healthy/h (9).jpg\"  \n",
    "\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    \n",
    "    with open(image_path, 'rb') as f:\n",
    "        display.display(display.Image(data=f.read(), width=500))\n",
    "else:\n",
    "    print(f\"File not found: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "\n",
    "\n",
    "image_path = \"Split/test/Fungal/01_0.png\" \n",
    "\n",
    "if os.path.exists(image_path):\n",
    "   \n",
    "    with open(image_path, 'rb') as f:\n",
    "        display.display(display.Image(data=f.read(), width=500))\n",
    "else:\n",
    "    print(f\"File not found: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_dataset(data, labels, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "train_data = data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    follow_links=True \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# I-set ang mga sukat ng imahe at batch size\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Gumawa ng ImageDataGenerator para i-rescale ang pixel values ng training at validation images\n",
    "train_data_gen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "valid_data_gen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# I-load ang training images mula sa direktoryo at i-process sa generator\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'Split/train',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# I-load ang validation images mula sa direktoryo at i-process sa generator\n",
    "valid_generator = valid_data_gen.flow_from_directory(\n",
    "    'Split/validation',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Gumawa ng Sequential model para sa convolutional neural network\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),  # First convolutional layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling layer para paliitin ang feature map\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Second convolutional layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Second max pooling layer\n",
    "    Flatten(),  # Flatten layer para i-transform ang 2D data sa 1D\n",
    "    Dense(128, activation='relu'),  # Fully connected layer na may 128 units\n",
    "    Dropout(0.5),  # Dropout layer para maiwasan ang overfitting\n",
    "    Dense(train_generator.num_classes, activation='softmax')  # Output layer para sa classification\n",
    "])\n",
    "\n",
    "# I-compile ang model gamit ang Adam optimizer, categorical crossentropy na loss, at accuracy bilang metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping callback para matigil ang training kapag walang improvement sa validation loss\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,  # Itigil ang training pagkatapos ng 5 epochs na walang improvement\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Ibalik ang best weights kapag natapos ang training\n",
    ")\n",
    "\n",
    "# I-train ang model gamit ang train_generator at i-validate gamit ang valid_generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=[early_stopping]  # I-apply ang early stopping sa training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "\n",
    "figure(figsize=(25, 25), dpi=100)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(2, 1, 1)  \n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(2, 1, 2)  \n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "The file contains only weights. You need the original model architecture to load them.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"EcomistModelV2.h5\"  # Adjust the path if needed\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(\"Loaded a full model (architecture + weights).\")\n",
    "    model.summary()  # Print model architecture\n",
    "except:\n",
    "    print(\"The file contains only weights. You need the original model architecture to load them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 224, 224, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 112, 112, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 56, 56, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 28, 28, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 423748 (1.62 MB)\n",
      "Trainable params: 422788 (1.61 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n",
      "✅ Model rebuilt & weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input\n",
    "\n",
    "def build_model():\n",
    "    input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Convolutional Block 4\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Feature Extraction\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output Layer (Update based on class count)\n",
    "    output_layer = Dense(4, activation='softmax')(x)  # Update with correct number of classes\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Rebuild the model\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights(\"EcomistModelV2.h5\")\n",
    "\n",
    "print(\"✅ Model rebuilt & weights loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predictions: [[1.2593208e-03 2.7327300e-05 9.9869269e-01 2.0632433e-05]]\n",
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load a test image (replace with an actual image path)\n",
    "img_path = r\"SplitV2\\test\\Healthy\\-_jpg.rf.a2935bd9f9dc97942b14b598c4c16012.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize\n",
    "\n",
    "# Make a prediction\n",
    "predictions = model.predict(img_array)\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Predicted class:\", np.argmax(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4274 images belonging to 4 classes.\n",
      "Class Index Mapping: {'Bacterial': 0, 'Fungal': 1, 'Healthy': 2, 'Lettuce': 3}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths (make sure these are correct)\n",
    "train_dir = \"SplitV2/test\"\n",
    "\n",
    "# Recreate ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)  # Ensure the same preprocessing as before\n",
    "\n",
    "# Load training data again\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Now get class labels\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"Class Index Mapping:\", train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: LettuceModelV2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LettuceModelV2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded from SavedModel format!\n"
     ]
    }
   ],
   "source": [
    "# Save as TensorFlow SavedModel format\n",
    "model.save(\"LettuceModelV2\")\n",
    "\n",
    "# Load the saved model when needed\n",
    "loaded_model = tf.keras.models.load_model(\"LettuceModelV2\")\n",
    "\n",
    "print(\"✅ Successfully loaded from SavedModel format!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
